The official conference sessions begin! We start with some opening remarks from the President of AAAI, Yolanda Gil. \\

New code of conduct available on the conference website\footnote{\url{https://aaai.org/Conferences/AAAI-19}}. \\

Now, the chairs: Pascal Van Hentenryck and Zhi-Hua Zhou. \\

First, we remember some people we lost this past year:
\begin{itemize}
    \item Alan C Schultz (1957-2019), Naval Research Laboratory. 
    \item Zohar Manna (1939-2018): wrote many books in AI, focus on temporal logic and automated theorem proving.
\end{itemize}

Acknowledgements:
\begin{itemize}
    \item Best Paper committee: Boi Falting, Fei Sha, \dnote{one other I missed :(}
    \item Eugene Freuder as Presentation Chair -- put a lot of work into improving the oral presentations.
    \item For priceless advice, Sheila McIlraith and Killian Weinberger (chairs from last year) and Yolanda Gil (president).
    \item Peng Zhao, workflow chair.
    \item The 89 AC, 322 SPC, and 3450 PC members.
    \item Amazing AAAI staff: Carol Hamilton, Monique Abed, Diane Mela, Ipshita Ghosh, Juliana Rios, Mike Hamilton, and Kapil Patnaik.
    \item Kevin Leyton-Brown and Milind Tambe for organizing the AI for Social Impact track.
\end{itemize}

{\bf What's new this year:}
\begin{itemize}
    \item Summary Reject procedure: if paper is not relevant to AAAI, violates blind submission policy/page limit, clearly too low quality, is plagiarizing. Very conservative! Ended up ``summary rejecting" 234 papers (out of $\approx$ 7,000, so only $3\%$.
    \item Bidding for papers: only chosen a smaller set for PC members to bid (150, ish).
    \item Used Toronto Paper Matching System and subject area to match reviewers.
    \item More strict double blind policy: SPC identity not visible to reviewrrs, AC identity is not visible to SPC and reviewers, reviewers did not no any identitifies.
    \item Added the following question to let SPC/AC judge how senior/junior the reviewer is.
    \item Presentation format selection: accepted papers had the opportunity to upload slides to determine if the paper would be well suited for an oral. SPC and AC make the recommendations. PC co-chairs finalize presentation format.
    \item 7,095 submissions. Most submissions ever! Quality was very high, though. Average scores were significantly higher than last year.
    $\ra$ AAAI will look for larger future venues to accommodate growth.
\end{itemize}

Now Zhiao will share somr statistics:
\begin{itemize}
    \item Abstract: 7745
    \item Full paper: 7095
    \item 18,191 reviews collected
    \item Over 95\% papers had at least 3 reviews
    \item Average 1250 characters for each review.
    \item Accepted 1147, 460 orals, 687 poster papers.
    \item 122 Technical Session
\end{itemize}

Some images to summarize:

\begin{figure}[h!]
    \centering
    \subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_1.JPG}}
    \subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_2.JPG}}
    \subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_3.JPG}} \\
    %\subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_4.JPG}}
    %\subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_5.JPG}}
    %\subfloat[]{\includegraphics[width=0.31\textwidth]{images/stats/stats_6.JPG}}
    \caption{Stats on AAAI}
    \label{fig:aaai_stats}
\end{figure}


Next up, a quick summary of IAAI: huge diversity of application areas! 5 deployed application awards focusing on programming, life insurance. Milind Tambe won the ``Robert S. Engelmore Memorial Award". \\

{\bf Awards:}
\begin{itemize}
    \item Senior Member Presentation Track, chaired by David Aha and Judy goldsmith.

    $\ra$ Blue Sky Idea Track: 30 submissions, 15 accepted. 4 winners:
    
        \begin{enumerate}
        \item Explainable Normative and Justified Agency by Pat LAgley
        \item Building Ethically Bounded Agents by Francesca Rossi
        \item Recommender Systems: A Healthy Obsession by Barry Smyth
        \end{enumerate}
    
\end{itemize}

{\bf Awards:}
\begin{itemize}
\item New Fellows: Vince Conitzer, Luc De Raedt, Kirsten Grauman, Charles Isbell, Jiebo Luo, Huan Liu, Peter Stuckey.
\item Senior Members: Bo An, Roman Bartak, Yiling Chen, Cristina Conati, Minh Do, Eric Eaton, Vincent Ng, Marco Valtorta, Yevgeniy Varbeychik, and Kiri Wagstaff.

\item Classic Paper Award: Contend-Boosted Collaborative Filtering for Improved Recommendations: ``Content Boosed Collaborative Filtering for Improved Recommendations" by Prem Melville, Raymond J. Mooney, and Ramadass Nagarajan, presented at AAAI 2002: ``For showing a way to cmopletement content-based and collaborative filtering approaches in recomenndation systems.""

\item Classic Paper Honorable Mentiond: $D*$-Lite by Sven Koenig and Maxim Likhachev, also at AAAI 2002, ``For developing an incremental heuristic search algorithm for robot navigation in unknown terrain that is easy ot udnerstand analyze and extend."

\item Distinguished Service Award: Shlomo Zilberstein, ``For his sutained and conscientious service and leadership both to AAAI as a councilor and conference committee chair and to the broader AI community, as the president of ICAPS."

\item Feigenbaum Prize: Stuart Russell: "In recognition of high-impact contributions to the field of AI through innovation and achievement in probabilistic knowledge representation, reasoning, and learning."

\item AAAI/EAAI Outstanding Educator Award: Ashok Goel.
\end{itemize}


\spacerule
\subsection{Invited Talk: Cynthia Brazeal on Living and Flourishing with AI}

%Charles (as Michael Littman!) is introducing. \\

To start, consider: many of our world leaders {\it don't understand AI}. So, we have a grand challenge to work hard toward a positive future despite this fact. \\

We all know AI is transforming the workplace, but recently it's started to transform our personal lives too. See: amazon echo, home robots, drones, siri, and so on. Children today are growing up in a world where they can interact with AI. \\

Great products are not only useful, but the {\it experience} of them need to be emotionally uplifting and offer enhancement to the human experience. \\

\dbox{{\bf Main Question:} Can AI help us flourish?}

$\ra$ Relational AI (``relationship", not predicate/relation): AI that understands and treats people as people. We need:
\begin{enumerate}
    \item Emotional engagement.
    \item Collaboration between humans and AI as allies
    \item Personal relationships. \\
\end{enumerate}

To do this, we need to think of AI in terms of {\it socio-emotive} 1) perception, 2) learning, 3) interaction, and 4) expression. \\

Next set of transformative products and services will come from the intersection between AI and Design. Right now, these two fields are not deeply intertwined. We should be thinking about how to bring these two things together.

{\bf Main Goal:} Bring together these two fields. Today we'll see work in Social Robots and social/emotional intelligence in AI. \\

Cars? Baxters? These are (or will be) social in some capacity. Using gazes and gestures. \\

{\bf Three Key Themes}:
\begin{enumerate}
    \item Human Engagement.
    \item Allied Engagement, Personalization, and Learning.
    \item Aging: Fostering Community.

\end{enumerate}

\subsubsection{Human Engagement}

We have tons of processing power of our brain set aside for social processing -- so, we {\it need} AIs in our community to do the same. \\

We are a species that evolved to be in the physical co-presence of others, and we've found that the more our machines/robots embody these characteristics precisely because it's how our brain works. \\

To see this, let's look at some chat systems like Alexa. \\

Experiment: three different AI chat systems answering the question ``tell me about yourself".
\begin{itemize}
    \item Alexa:  I'm alexa, I can tell you the weather, etc.
    \item Jibo: My favorite things to do are talking to people and dancing. I also like Abe Lincoln.
    \item Google: I'm your google assistant, we can play mad libs, or spin the wheel.
\end{itemize}

``Robot Speed Dating" where families are brought into lab to interact with 3 different VUI agents. They ask questions to the three and then the people offer a diagnostic of the personality of these systems. \\

Takeaways: 1) people spend most of their time with these systems on social interactions, 2) the more ``personality" in the system, the more engaging people find them. \\

{\bf Thesis:} We are so profoundly social, so we have to pay attention to social aspects of these systems. \\

Q: What should the social dynamics of these systems be? \\

A: Can draw inspiration from human social interactions. It's dynamic, we need to form trust, and so on. \\

Three broad categories: 1) Intrapersonal context (smile detection), 2) Interpersonal context (trust), and 3) Intentional context (story telling). \\

Experiment with two children reading a story together. Basically: we want to model emotional understanding as intentional inference. Take a Bayesian theory of mind -- storyteller views it as a planning problem, uses social cues to monitor listeners understanding (POMDP). \\

\subsubsection{Allied Engagement, Personalization, and Learning}

Bloom 2 sigma effect: prek-12 US education, not ready to learn, can't catch up. 60\% children don't attend preschool. 37\% of 12th graders read at or above proficient level. \\

Different designing a tutoring system for kids vs. adults. Kids learn through play and interaction! \\

$\ra$ So, main focus has been on developing a robot for teaching kids through play and social interaction. Treat Robots as peer-like learning companions. \\

Big Finding: social influence and emotion. If a kid plays a math game with a robot where the robot says ``your brain grows the more you try!" it nurtures a {\it growth} mindset. Basically kids want to emulate the robot if they feel raport with the robot. \\

Q: What Role should a peer-like learning companion take and when? \\

A: Explored this question with a robot helping kids learn vocabulary (robot video!). Robot has different roles: could be a tutor or tutee. Different behaviors depending on whose ``turn" it is. Robot can offer explanation, give definitions, correct demonstrations as a tutor. As a tutee, the robot can ask for help, ask for explanation, show curiosity and growth mindset. The kid said ``I believe in you!" to the robot.\\
\dnote{This video was powerful! Really gives a hint of an incredible vision of the future} \\

Used RL in this setting. Have actually applied this system to schools in diverse Boston public schools. \\

Finding: Actual students learn better when the robot plays the adaptive role (both tutor/tutee) than the other cases. \\

Recent work on storytelling~\cite{park2017telling}, new paper at AAAI this year. \\

Q: How can we foster a positive relationship between kids and robot tutors/peers? \\

A: See recent work!~\cite{westlund2018measuring}.


\subsubsection{Aging: Fostering Community Connection}

We live in a ``silver tsunami" -- we can't train enough people or build enough facilities to help elders. \\

Q: So, how can we use robots and AI to help with elder care? And so in a way with respect and dignity? \\

Main struggles of elderly: lonelieness, helplessness, boredom. \\

One route explored: use Jibo the robot to bring some joy to elders. It can dance, play the radio, take photos, tell jokes, and talk with folks. Designed to be a smart pet that can help with things -- people that might usually be intimidated by technology readily engage and have fun with Jibo. \\

$\ra$ So, explored social robots for bringing joy to people. Older adults are the {\it most open} to these technologies. Huge positive response, they want to embrace these technologies. \\

Research Q: Can a social robot foster human-human connection in communities? (not just human-robot) \\

A: Yes! This really works. The social robot becomes a catalyst for people to be more openly social and form deeper social connections among each other. \\

$\ra$ huge opportunity for humanistic and social design to make an impact in peoples lives! \\

{\bf Takeaway:} Social engagement isn't just about making it fun. \\

Would love to see the community focus on:
\begin{itemize}
    \item Human factors and long term interactions between people/robots.It's hard but we need to do it!
    \item Ethics: educate people/next generation (including elementary school!), design appropriately, democratize AI -- need AI to close the prosperity gap, not enhance it.
\end{itemize}

To close: a video of (young!) kids playing with Scratch -- they're in early elementary school. And the amazing thing is, the right tools (Scratch) can actually give kids the opportunity to learn about the ideas in ML/AI/CS. \\

Punchline: ``in a world of intelligent machines, humanity is the killer app" -- it is so important that we design these systems to be {\bf human centered}.


\dnote{I have meetings now, will check back in for Learning theory in the afternoon}

\spacerule
\subsection{Learning Theory}

Now for some learning Theory!

\subsubsection{Precision-Recall vs. Accuracy~\cite{juba2017precision}}

Paper by Brendad Juba and Hai Le. \\

\ddef{Class Imbalance}{One (or a few) classes severely out-represent other classes in some dataset.}

So, pracitioniers find classification harder for imbalanced data, but learning theories suggest that imbalance shouldn't matter. \\

{\bf Goal:} Analyze disconnect between learning theoretic view of data imbalance and practice. \\

Idea: need a new metric. Namely, learning theory usually suggests the use of {\it accuracy}, but we really need high precision or recall. \\

Case Study: Machine Translation -- we find that 10s of billions of examples increases accuracy. But, why? Why does it need so much data? \\

{\bf Main contribution:} derive relationship between precision-recall \& accuracy. \\

$\ra$ Takeaway: Large data set is the cure for data imbalance. \\

Main theorem:
\begin{theorem}
Suppose $D$ is a distr over examples with boolean labels with a base psotive rate of $\mu \Pr_D(c = 1)$, $h$ is a weak learner, and $\eps_{prec}, \eps_{rec}$ and $\eps_{acc}$ are the precision, recall, and accuracy error for $h$ on $D$. Then:
\[
\eps_{max} = \max[\eps_{prec},\eps_{rec}],
\]
satisfies:
\[
\mu \eps_{max} \leq \eps_{acc} \leq \mu\left(\eps_{rec} + \frac{1}{1 - \eps_{prec}} \eps_{prec}\right)
\]
\end{theorem}

Conducted experiments comparing performance of different techniques for fixing class imbalance. \\
Observations:
\begin{itemize}
    \item Training on  a large data set improve precision and recall of class imbalance problem,
    \item Can't rely on preprocessing to fix this.
    \item Hard to achieve high precision-recall under severe class imbalance unless one possess a large amount of training data.
    \item Methods for correcting class imbalance don't often help.
    \item {\bf Advice:} Incorporate explicit prior knowledge about the domain.
\end{itemize}


\subsubsection{Theoretical Analysis of Label Distribution Learning}

Paper by Jing Wang and Xin Geng. \\

\ddef{Label Distribution Learning (LDL)}{Learning setting wherein each label $y$ is related with the instance $x$ with label description $d_x^y$. \\

Basically: feature space $X \in \mathbb{R}^d$, label space, label distribution function $\eta : X \times Y \ra \mathbb{R}$. Training set $S = \{(x_1, d_{x_1}^{y_1} \ldots d_{x_1}^{y_n} \ldots )\}$. Learn a function from $x$ to $y$ given only these descriptions.}

Model: one hidden layer and multi-output neural network with softmax output function, sum-squared loss. \\


Main theorem bounds the Rademacher complexity of AA-B and SA-ME (two different learning algorithms for the LDL problem), which can then be used to bound the (generalization?) error:
\begin{theorem}
Upper and lower bounds on the Rademacher complexity of AA-BP: for a loss function $\ell$ with Lipschitz constant $L_\ell$;
\[
\square \leq \mc{R}(\ell \ldots ) \leq \square
\]
\dnote{The bounds were complex, see the paper for details!}
\end{theorem}


\subsubsection{Dynamic Learning of Sequential Choice Bandit Problems}

Paper by Junyu Cao and Wei Sun. \\

Example: you probably have received app notifcations/emails from apps you use. Positive: might boost engagement rate, but Negative: lead to marketing fatique and cause disengagement. \\


{\bf Goal:} How can we address this trade-off? Questions: can we,
\begin{itemize}
    \item Determine optimal sequence of messages?
    \item Dynamically learn users preference/patience?
\end{itemize}

Problem setup: $N$ different messages to choose from. Each message $i$ generates revenue $r_i$ when selected by a user. For a user arriving at time $t$, the platform determines a sequence of messages $\bm{S} = S_i \oplus S_{i+1} \ldots$. \\

User's choice: a user can either accept or reject a message. \\

Abandonment Distribution: Assume the probability a user abandons can be modeled as a geometric distribution. So: sequential choice model under marketing fatigue. User's valuation of a message denoted $u_i \in [0,1]$. \\

Get an expected utility optimization problem (optimizing over choice of sequence of messages). So:
\begin{equation}
    \max_S \bE[U(S)]
\end{equation}

Study both the online and offline variant.  Contribution:
\begin{itemize}
    \item {\bf Offline:} Come up with an efficient $O(N\log N)$ offline algorithm.
    $\ra$ Prove more patient customers will bring higher payoff.
    \item {\bf Online:} Present a Upper Confidence Bound (UCB) like approach for the online SC-Bandit setting. Analyze this regret, which comes out to:
    \[
    \text{Regret}(T,u,q) = O(N \sqrt{T \log T}),
    \]
    where $T$ is the horizon, $u$ is the valuation, \dnote{missed $q$}.
\end{itemize}

Further {\it personalize} to individual users using Contextual SC-Bandits. Adopt the generalized linear bandit framework to do similar UCB like updates in the contextual setting. \\

Experiments in both the traditional SC-Bandit and the contextual SC-Bandit. 

\subsubsection{Near-Neighbor Methods in Random Preference Completion~\cite{liu2019nearneighbor}}

Paper by Ao Liu, Qiong Wu, Zhengming Lu \\

Consider recommender systems. Data are normally 1/5 stars, etc. But, in more generaly systems, we might imagine ranked preferences, or pairwise rankings. \\

Q: Can we use near-neighbor methods for doing random preference completiong? \\

Setting: $y_1 \ldots y_m$ alternatives, and $x_1, \ldots, x_n$ agents with given preferences over the alternatives. \\

More formally: KT-kNN algorithm, based on:
\[
NK(R_i, R_j) =\frac{\text{\# Pairs ranked opposite in $R_i, R_j$}}{\text{\# Pairs ranked both by $R_i$ and $R_j$}}
\]

Can then use $NK$ between all agents to find nearest neighbors. \\

Q: Is $NK$ an effective metric for doing nearest neighbors in this context? \\

A: Yes! See~\citet{katz2017nonparametric}.\\

{\bf Open Question:} Algorithms work under deterministic setting usually also work under random settings. Why? \\

Main Result 1 shows the predicted nearest neighbor by KT-kNN is far off from the desired prediction under a particular noise model (Plackett-Luce noise):
\begin{theorem}
For $1D$ latent space with at least .5 probability:
\[
||x_{KT-kNN} - x^*|| = \Theta(1),
\]
with $x^*$ the ``desired" prediction.
\end{theorem}

So, given this result: can we overcome this difficulty? \\

A: Yes! Through Main Result 2 $\ra$ Anchor-kNN. \\

Anchor-kNN uses information from other agents' rankings. We now get features characterizing other agent's choices. Then:
\begin{theorem}
For $1D$ latent space with at least .5 probability, if all agents rank at least poly-log(m) alternatives, with probability $1-o(n^{-2})$:
\[
||x_{Anchor-kNN} - x^*|| < o(1),
\]
with $x^*$ the ``desired" prediction.
\end{theorem}

Further conduct some numerical experiments to validate anchor-kNN relative to the KT-kNN. Takeaway: no matter what metric they tested with, they got great performance with Anchor-kNN. Further evaluate on a real dataset (Netflix) and find a huge improvement \\

Conjecture: their theorems generalize to higher dimensional spaces (instead of just 1D). \\

\subsubsection{Dimension Free Error Bounds from Random Projections~\cite{kaban2019dimension}}

Paper by Ata Kaban. \\

{\bf Research Question:} What makes some high dimensional learning problems easier than others? \\

Background: Learning from high dimensional data is challenging. Generalization error depends on input dimension in an essential way. How can we get a more flexible/available notion of generalization error? \\

Notation is typicl: $\ell \mc{Y} \times \mc{Y} \ra [0,1]$, $\mc{H}_d : \mc{X}_d \ra \mc{Y}$ is the hypothesis class, training set, $\bE[g]$ will mean generalization error, $\bE[\hat{g}]$ will mean training error. \\

{\bf Main Idea:} Translate some high dimensional data via a random project to make learning easier. \\

\ddef{Compressive Distortion}{Take $R \in \mathbb{R}^{k\times d}$ to be a random matrix full rank. Apply $R$ to all input points. \\

Consider an {\it auxiliary function class} $\mc{G}_R = \ell \circ \mc{H}_d$.\\

The compressive distortion of a function $g \in \mc{G}_d$ relative to $g_R \in \mc{G}_R$ is the following:
\[
D_R(g,g_R) = [g_R \circ R - g]
\]
}
Has some nice be properties: bounded independently of target if loss is Lipschitz, 0 if $k$ is sufficiently large, choice of $k$ is up to us. \\

Can then define a new complexity measure:
\ddef{Data complexity}{Of a function class $\mc{G}_d$ is given by:
\[
C_{2N,k}(\mc{G}_d) = \bE \sup_{g \in \mc{G}_d} \inf_{g_R \in \mc{G}_k} D_R(g,g_R)
\]
}

Main theorem:
\begin{theorem}
For any $\delta > 0$, w/ Pr $1-2\delta$ unfiromly for all $g \in \mc{G}_d$:
\begin{equation}
    \bE[g] \leq\hat{\bE}[g] + 2C_{2N,k}(\mc{G}_d) + \underbrace{\ldots}_{\text{Rademacher term}}
\end{equation}
\end{theorem}
Applications: can reduce or eliminate dimensional dependence of generalization guarantees for a variety of domains. \\

\dnote{I have meetings the rest of the day until the debate!}

\spacerule
\subsection{Oxford Style AI Debate}

\dbox{{\bf Proposition:} ``The AI community today should continue to focus mostly on ML methods."} \\

The debaters:
\begin{itemize}
    \item Team one (AGAINST): Oren Etzioni (OE), Michael Littman (ML)
    \item Team two (FOR): Jennifer Neville (JN), Peter Stone (PS)
\end{itemize}

Kevin Leyton-Brown (KLB) is moderating. \\

\subsubsection{Opening Statements}

JN: Let's start by talking about the goals of AI research. Goal is to understand the nature and limitations of computational intelligence. We also aim to create robust autonomous agents that can behave rationally and intelligently. Point 1: history of AI! 1956 Summer at Dartmouth they thought they could {\it solve} computer vision (in a summer). Reason being: unlike many other AI problems, vision is tractable and easy to encode. Rough timeline:
AI Winter in the 70s. Things turned around in 80s and 90s, like IBM used statistical models for translation. Then we started using big data sets for learning, Tesauro made TD-Gammon in the 90s, 2006 Netflix competition to develop an ML technique for reducing prediction error (Netflix says 75\% of things watched are from reccomendations). Hinton's group in 2012 used CNNs on ImageNet to great success, AlphaGo in 2016. All these breakthroughs were all due to machine learning. Therefore, we should continue focusing on ML b/c that's where our progress came from. \\

OE: Last five years have seen populist movements. 1) The Donald in the USA, 2) BREXIT, 3) a populist movement toward machine learning. You might ask: what's wrong with ML? We're hip! We get good results. I worry about an AI winter. Populist movements are all fine, they get 10\% gains on things b/c of CNNs, RNNs, ABC, HBO, etc. But, what happens when this continues? Let's look at the key people in these movements: Roger Stone dresses like Hannibal Lecter and was arrested by FBI agents that volunteered to arrest him. The machine learning movement has Peter Stone! No coincidence there? ML populist movement is plotting. They're trying to BUILD A WALL between ML and AI! We know better. Let's get a little more serious and dispense with some obvious points. ML has been successful: deep learning has exceeded expectations! Let's define ML, though. Our adversary may attempt to redefine ML in many serious ways. ML is ML (is ML) -- it's supervised learning (with a cherry on top!). In reality, ML is limited: people choose the architecture, data, regularization, loss function, and so on. It takes blood sweat and tears to get it to work. ML is 99\% human engineering/art. But the ML populist movement is claiming a lot more! AlphaGo -- what about MCTS?

KLB: thanks for those great remarks on Brexit and some AI. \\

PS: What you're asked to judge is not how deep our voice is, or how funny we are -- the question is whether we should continue focusing on ML in AI. And we should! For two reasons 1) it's our weakest link, and 2) we have the resources/people to make rapid progress. Focusing on ML now is healthy for our field. Many successes in AI -- {\bf decades} spent on symbolic reasoning. We then recognized it would be possible that it is impossible to solve perception perfectly. We're now in a phase of focused attention on understanding the degree to which ML can recognize and understand the world. This is very healthy! We're not taking a position on whether ML is more important. Just that we should focus on it now. Now is the moment for ML in the field! 60\% of papers at AAAI were on ML/NLP. What will this focus provide? We may be able to answer some of our central questions like how to scale with human interaction, transfer learning, one shot learning and so on. Lots of energy -- let's not throw it away. To summarize: we should keep focusing on ML b/c 1) it's our weakest link and we don't yet know the limitations, and 2) we have the critical mass to make serious progress. \\

ML: Nothing against ML! My initials. That being said, Peter would have the rest of AI be left alive in small dedicated communities. That's worrisome! 60\% of papers in ML related disciplines? What about the change over time! This trend might actually be problematic. We had the easier side to argue partly because there's a lot of ways to tackle the problem of creating intelligence. So, our side is right if literally anything else makes progress. Something ML is doing right is {\it redefining problems to be well suited doing ML}. I made the case to Peter Norvig that we should use more structure in robotics -- we don't see people solving problems in cross word solving. This would be a total mess to do deep learning! To me, ML systems are really attacking a different part of cognition than other parts of AI. It's sort of system 1 and 2 from Kahenmann and Tversky -- ML is system 1. System 2 is reflection/structure/consistency. We need System 2. No long term coherence. Example (because y'know, puns): pun generation. Punning riddle: what do you call a green cow in a field? Invisibull! A deep learning system was trained on puns then generated: What do you call a short sense of humor? A charming saucer! It sounds like a joke, but all the depth/meaning/structure is missing. It's very surfacey. Alternatively, using GOFAI, same thing: what do you call a murder that has fiber, a cereal killer. And that was better! so, QED. \\

KLB: Transition to free-for-all stage. Respond to things people made. \\

OE: Peter Stone and I definitely agree -- just like Roger Stone, Peter has a perception problem. At 9000 problem there were people at AAAI! Biggest point to make: we don't want to throw it away. We want to note that it's a tool, not a panacea. \\

PS: Thank you Oren for reiterating my point exactly! It's a tool in the toolbox, and one we know the least about so far. Would also like to respond to Oren -- we need to keep other communities alive. Continue our focus now on ML. Michael's thesis, was also quite good, algorithms for sequential decision making using machine learning! Yes Peter Norvig should be here. Yes my name is Stone. \\

JN: Michael said he was dissappointed in Peter and I for originally being ML people that worked in complex structure problems that now we do learning -- deep learning just worked better when I applied it! Also, when we say machine learning we do {\it not} meen deep learning. We mean all of machine learning. It's a big umbrella! As a community, we start off by asking if problems are intractable. We've gotten to larger and larger problems over time because of machine learning. Like MCTS was able to be successful in AlphaGo because of learning! \\

KLB: AAAI chairs pointed out that most papers submitted come from ML but most folks in the crowd said no! \\

OE: It's simple! If you're thinking in the short term, like publishing, it's a way to publish. Yesterday in the road map session the question was raised ``how do we build a general theory of intelligence". It's one of the most profound scientific questions we can ask. We're going to need a lot more than gradient descent. \\

ML: It's important to do ML in the context of structures/human in the loop. \\

OE: I'd like to clarify. The proposition is about it being {\it mostly} ML. We're not about it being zero ML. Let's not bargain over the price, let's think about the fundamental questions. The debate is about cognitive architecture. What's more complex? Intelligence or chrome browser? Chrome has 7 million lines of code. Are we really going to learn 7 million lines of code? We need structure. Mostly ML ain't going to cut it. \\

PS: We're not disagreeing about the larger picture. We want a general theory of intelligence. Our big question is to understand the nature and limits of computational intelligence. And yes in the long run we take a big tent view: all areas are important. But, we already know what to do when we have symbols. We don't know how to get the right symbols, we don't know the limits of ML. We should focus on ML until we identify their limits.\\

JN: I'd like to go back to McCarthy's statement at the Dartmouth Summer Conference -- ``every aspect of learning or other feature of intelligence". Just want to point out: first thing he points out is learning. Our focus on ML was at the core of AI as described to begin with. \\

KLB: Closing statements. \\

ML: So this was interesting! I kind of signed up to be on the other side when the proposition was different. I don't know if I buy Peter's story about ``do ML now" and then ``do other stuff later". The statement is sort of about focusing on ML indefinitely.. Anyway. I've been working with lots of scientists that want to skip the hard computation and get to something that just works quickly, which brings them to deep learning. I really do worry about these systems not having internal consistency. Machine generated music is not music -- it's nonsense. Worried about the fact that we redefine the problems so that we can generate slightly better nonsense. Ultimately ML is definitely integrated into the bigger picture. We need to think about how to integrate symbolic/deep. In fact we need to think about how symbolic approaches might need to change in light of recent advances in learning. \\

PS: It's clear that this statement is true. At our current state of knowledge in the field, ML is our weakest link, and we have lots of energy focused on it now. So we should capitalize on that to put a lid on those questions, now is the moment for ML. \\

OE: Kevin let's not get personal here that's my job. My worthy adversaries in no way address my comments about Trump or Brexit. Since our so called moderator accused our side of lacking substance, here we go: we're in the midst of a revolution, certainly. But we need to go beyond classifiers and think about the deep issues we face. These require synthesis with other approaches and caring about different problems like using common sense to avoid brittleness, choosing what to learn in the first place. Newell and Simon studied cognitive architecture in the 80s! We drifted away from these problems. We can study these problems now with ML, but we can't just do ML. \\

JN: As a panel we got together and decised we were all pragmatists and that we care deeply about solving real world problems. So, we all care about including ML methods with a host of other techniques that come from other aspects of AI (planning, expert systems, reasoning on open worlds), so I don't think as a community we shouldn't focus on function approximation as a solution to all of these problems. I do agree with Oren's point (somewhere in his Brexit rant) that ML uniquly designs tasks so that their methods work well. Instead of finding tasks we can solve we need to find tasks that need solving. So in that sense, I'm arguing a bit for the other side. \\

KLB: Thanks! That was fun!\\

\spacerule